{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "q08oX1r8Fd0j",
        "xGaVkwD3uRa_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports + Setup"
      ],
      "metadata": {
        "id": "em7CDjxwFYN2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hg73JcHQFXb"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import urllib.parse\n",
        "import json\n",
        "import os\n",
        "from IPython.display import Audio, display\n",
        "import random\n",
        "import librosa\n",
        "import librosa.effects\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.data import Dataset\n",
        "from tensorflow.data import AUTOTUNE\n",
        "from tensorflow import TensorSpec\n",
        "from tensorflow import dtypes\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from google.colab import drive\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "SR = 22050\n",
        "INPUT_SHAPE = (1025, 130)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/Shareddrives/2022 FIRE COML STUDENTS/Fall/Product Teams/Team 2/MuPr')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akUHnedMF1KI",
        "outputId": "72ccfafa-095c-498c-c439-48cc659125b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Setup"
      ],
      "metadata": {
        "id": "3b1nJOzTFqTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 4\n",
        "num_epochs = 10\n",
        "patch_width = 1\n",
        "num_patches = INPUT_SHAPE[1] // patch_width\n",
        "projection_dim = 16 #256\n",
        "num_heads = 4\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "]\n",
        "transformer_layers = 1 #8\n",
        "mlp_head_units = [16, 8] #[512, 256] #[2048, 1024]\n",
        "embedding_length = 16 #128"
      ],
      "metadata": {
        "id": "OXMhNIku0fIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Triplet Generator Class\n",
        "class ClipTripletGenerator():\n",
        "    def __init__(self, triplet_dir, batch_size=4, input_shape=INPUT_SHAPE):\n",
        "        self.triplet_dir = triplet_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "    def generate(self):\n",
        "        for triplet in os.listdir(self.triplet_dir):\n",
        "            try:\n",
        "                a, p, n = np.load(os.path.join(self.triplet_dir, triplet), allow_pickle=True)\n",
        "            except:\n",
        "                print(f'Failed to load {triplet}')\n",
        "                continue\n",
        "            yield (a, p, n), None\n",
        "\n",
        "    def get_generator(self):\n",
        "        inp_ts = TensorSpec(self.input_shape, dtypes.float32)\n",
        "        datagen = Dataset.from_generator(\n",
        "                      self.generate, \n",
        "                      output_signature=((inp_ts, inp_ts, inp_ts), TensorSpec(None))\n",
        "                  )\n",
        "        return datagen.batch(self.batch_size).prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "pN0vU4PhQrph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen = ClipTripletGenerator('triplets')\n",
        "generator = gen.get_generator()"
      ],
      "metadata": {
        "id": "tcNUuX4AOuPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "_teOUbyQ1M3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Patches(layers.Layer):\n",
        "    def __init__(self, num_patches):\n",
        "        super(Patches, self).__init__(name='Patches')\n",
        "        self.num_patches = num_patches\n",
        "        self.patch_width = INPUT_SHAPE[1] // num_patches\n",
        "\n",
        "    # def build(self, input_shape):\n",
        "    #     self.batch_size = input_shape[0]\n",
        "    #     super(Patches, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        inp = tf.reshape(inputs, [batch_size, INPUT_SHAPE[0], INPUT_SHAPE[1], 1])\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=inp,\n",
        "            sizes=[1, INPUT_SHAPE[0], self.patch_width, 1],\n",
        "            strides=[1, INPUT_SHAPE[0], self.patch_width, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\"\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches"
      ],
      "metadata": {
        "id": "IPxGaelC69Gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__(name='PatchEncoder')\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "    \n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        proj = self.projection(patch)\n",
        "        pose = self.position_embedding(positions)\n",
        "        encoded = tf.reshape(proj, [-1, num_patches, 16]) #should be 'encoded = proj + pose'\n",
        "        return encoded"
      ],
      "metadata": {
        "id": "kSTIf2dfZTDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletLossLayer(layers.Layer):\n",
        "    def __init__(self, alpha, **kwargs):\n",
        "        self.alpha = alpha\n",
        "        super(TripletLossLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({'alpha': self.alpha})\n",
        "        return config\n",
        "\n",
        "    def triplet_loss(self, inputs):\n",
        "        a, p, n = inputs\n",
        "        p_dist = K.sum(K.square(a-p), axis=-1)\n",
        "        n_dist = K.sum(K.square(a-n), axis=-1)\n",
        "        #return K.sum(K.maximum(p_dist - n_dist + self.alpha, 0), axis=0)\n",
        "        return K.sum(p_dist - n_dist + self.alpha, axis=0)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        loss = self.triplet_loss(inputs)\n",
        "        self.add_loss(loss)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "BTGNWGPEsR0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_a = layers.Input(shape=INPUT_SHAPE, name='anchor_input')\n",
        "in_p = layers.Input(shape=INPUT_SHAPE, name='positive_input')\n",
        "in_n = layers.Input(shape=INPUT_SHAPE, name='negative_input')\n",
        "\n",
        "input = layers.Input(shape=INPUT_SHAPE, name='Input')\n",
        "#norm = layers.Normalization()(input) # Do we need / want this?\n",
        "patches = Patches(num_patches)(input)\n",
        "encoded = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "for _ in range(transformer_layers):\n",
        "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded)\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "    )(x1, x1)\n",
        "    x2 = layers.Add()([attention_output, encoded])\n",
        "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "    x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "    encoded = layers.Add()([x3, x2])\n",
        "\n",
        "representation = layers.LayerNormalization(epsilon=1e-6)(encoded)\n",
        "representation = layers.Flatten()(representation)\n",
        "representation = layers.Dropout(0.5)(representation)\n",
        "features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "output = layers.Dense(embedding_length)(features)\n",
        "\n",
        "embedding = keras.Model(input, output, name=\"Embedding\")\n",
        "\n",
        "emb_a = embedding(in_a)\n",
        "emb_p = embedding(in_p)\n",
        "emb_n = embedding(in_n)\n",
        "\n",
        "triplet_loss_layer = TripletLossLayer(alpha=0.4, name='triplet_loss_layer')([emb_a, emb_p, emb_n])\n",
        "\n",
        "model = keras.Model([in_a, in_p, in_n], triplet_loss_layer)\n",
        "model.compile(loss=None, optimizer='adam')#optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=None)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "1Oil2ez_LP27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ce12b44-a3cd-4511-a4db-d54021058838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " anchor_input (InputLayer)      [(None, 1025, 130)]  0           []                               \n",
            "                                                                                                  \n",
            " positive_input (InputLayer)    [(None, 1025, 130)]  0           []                               \n",
            "                                                                                                  \n",
            " negative_input (InputLayer)    [(None, 1025, 130)]  0           []                               \n",
            "                                                                                                  \n",
            " Embedding (Functional)         (None, 16)           52104       ['anchor_input[0][0]',           \n",
            "                                                                  'positive_input[0][0]',         \n",
            "                                                                  'negative_input[0][0]']         \n",
            "                                                                                                  \n",
            " triplet_loss_layer (TripletLos  ()                  0           ['Embedding[0][0]',              \n",
            " sLayer)                                                          'Embedding[1][0]',              \n",
            "                                                                  'Embedding[2][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 52,104\n",
            "Trainable params: 52,104\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(generator, \n",
        "    epochs = num_epochs,\n",
        "    callbacks = [ModelCheckpoint(filepath='ckpts/no_transformer/epoch{epoch:03d}_loss{loss:.3f}.hdf5',\n",
        "                    monitor = 'loss',\n",
        "                    save_best_only = True,\n",
        "                    mode = 'auto',\n",
        "                    save_weights_only = True,\n",
        "                    verbose = 2),\n",
        "               # EarlyStopping(monitor='loss',\n",
        "               #               mode='auto',\n",
        "               #               patience=100,\n",
        "               #               verbose=True)\n",
        "                ])"
      ],
      "metadata": {
        "id": "0VPFy-kVsqvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "xGaVkwD3uRa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('ckpts/no_transformer/epoch007_loss-97146000.000.hdf5')\n",
        "base_model = model.get_layer('Embedding')\n",
        "embeddings = []\n",
        "for filename in os.listdir('songs'):\n",
        "    song, _, _, id = np.load('songs/'+filename, allow_pickle=True)\n",
        "    clip_secs = 3\n",
        "    clip_samples = clip_secs * SR\n",
        "    for start in range(0, len(song), clip_samples):\n",
        "        if start + clip_samples < len(song):\n",
        "            inp = librosa.stft(song[start : start + clip_samples])\n",
        "            emb = base_model.predict(tf.reshape(inp, [-1, inp.shape[0], inp.shape[1]]), verbose=0)\n",
        "            embeddings.append((emb, id))"
      ],
      "metadata": {
        "id": "LvcSlDWStUSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embedding_distance(embedding1, embedding2):\n",
        "  return np.sum(np.square(embedding1 - embedding2))"
      ],
      "metadata": {
        "id": "hQLJ1HVN0g_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to make a guess based on a 3 second numpy snippet\n",
        "def guess(snippet, extra_output=False):\n",
        "    inp = librosa.stft(snippet)\n",
        "    emb = base_model.predict(tf.reshape(inp, [-1, inp.shape[0], inp.shape[1]]), verbose=0)\n",
        "    emb_distances = [(embedding_distance(emb, e), id) for e, id in embeddings]\n",
        "    shortest_distances = sorted(emb_distances)\n",
        "    dist, id = shortest_distances[0]\n",
        "    if extra_output:\n",
        "        return id, dist, name, artist\n",
        "    else:\n",
        "        return id"
      ],
      "metadata": {
        "id": "gqPuThK2zvmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 77\n",
        "ts_filename = os.listdir('songs')[index]\n",
        "test_song, name, artist, id = np.load('songs/'+ts_filename, allow_pickle=True)\n",
        "\n",
        "augmentations = [\n",
        "    augment_noise,\n",
        "    augment_pitch, \n",
        "    augment_speed\n",
        "]\n",
        "aug_song = augment_data(test_song, augmentations)\n",
        "\n",
        "clip_secs = 3\n",
        "clip_samples = clip_secs * SR\n",
        "max_start = len(aug_song) - clip_samples\n",
        "start = int(random.uniform(0, max_start))\n",
        "test_snippet = aug_song[start : start + clip_samples]\n",
        "\n",
        "guess_id, dist, guess_name, guess_artist = guess(test_snippet, extra_output=True)\n",
        "print(f'Guess: {guess_name} - {guess_artist}')\n",
        "print(f'Actual: {name} - {artist}')\n",
        "print(f'Distance: {dist}')"
      ],
      "metadata": {
        "id": "iZcSamzA06BU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6445b14-faad-48fc-945f-3c79e648134c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Guess: Marc Anthony - Vivir Mi Vida\n",
            "Actual: Marc Anthony - Vivir Mi Vida\n",
            "Distance: 253.82632446289062\n"
          ]
        }
      ]
    }
  ]
}